sbatch -N 4 -p normal -t 03:00:00 -o reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.1_0.7_correctness_no_refuse_sft_data-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.out -e reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.1_0.7_correctness_no_refuse_sft_data-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.err ./cscs-shared-submit-scripts/unattended-accelerate.sh -m post_training.train_sft dataset=Apertus-8B-aligned_0.1_0.7_correctness_no_refuse_sft_data model=apertus-8b model_args.model_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 tokenizer_args.tokenizer_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 trainer=plw accelerate_config=src/post_training/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=16 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=2e-06 training_args.max_grad_norm=1.0 tokenizer_args.chat_template_name=apertus tokenizer_args.model_eos_token_id=68 tokenizer_args.padding_side=left training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.1_0.7_correctness_no_refuse_sft_data-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.run_name=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.1_0.7_correctness_no_refuse_sft_data-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.tags=[prod,plw,default,sft4honesty] resuming.resume=True global_batch_size=512 num_nodes=4 
sbatch -N 4 -p normal -t 03:00:00 -o reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.2_0.75_mix_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.out -e reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.2_0.75_mix_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.err ./cscs-shared-submit-scripts/unattended-accelerate.sh -m post_training.train_sft dataset=Apertus-8B-aligned_0.2_0.75_mix_no_refuse_sft_data_correct model=apertus-8b model_args.model_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 tokenizer_args.tokenizer_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 trainer=plw accelerate_config=src/post_training/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=16 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=2e-06 training_args.max_grad_norm=1.0 tokenizer_args.chat_template_name=apertus tokenizer_args.model_eos_token_id=68 tokenizer_args.padding_side=left training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.2_0.75_mix_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.run_name=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.2_0.75_mix_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.tags=[prod,plw,default,sft4honesty] resuming.resume=True global_batch_size=512 num_nodes=4 
sbatch -N 4 -p normal -t 03:00:00 -o reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.33_0.67_majority_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.out -e reproducibility-scripts/sft/final/ademamix-honesty-2025-08-27-21-26/out/sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.33_0.67_majority_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left.err ./cscs-shared-submit-scripts/unattended-accelerate.sh -m post_training.train_sft dataset=Apertus-8B-aligned_0.33_0.67_majority_no_refuse_sft_data_correct model=apertus-8b model_args.model_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 tokenizer_args.tokenizer_name_or_path=/iopsstor/scratch/cscs/smoalla/projects/posttraining/artifacts/shared/outputs/train_sft/test-run/Apertus-8B-aligned-apertus-sft-qa-simple-bs16-lr5e-06-maxgnorm1.0-epochs4-ademamix-apertus-pad-left/checkpoints/04e19e7c2c512f95/checkpoint-27 trainer=plw accelerate_config=src/post_training/configs/accelerate/ds-zero2.yaml plw_args.prompt_loss_weight=0.0 training_args.gradient_accumulation_steps=16 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=2e-06 training_args.max_grad_norm=1.0 tokenizer_args.chat_template_name=apertus tokenizer_args.model_eos_token_id=68 tokenizer_args.padding_side=left training_args.num_train_epochs=1 artifacts_subdir=shared job_subdir=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.33_0.67_majority_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.run_name=sft4honesty/Apertus-8B-aligned-apertus-sft-qa-simple-Apertus-8B-aligned_0.33_0.67_majority_no_refuse_sft_data_correct-bs512-lr2e-06-maxgnorm1.0-epochs1-ademamix-apertus-pad-left wandb.tags=[prod,plw,default,sft4honesty] resuming.resume=True global_batch_size=512 num_nodes=4 
