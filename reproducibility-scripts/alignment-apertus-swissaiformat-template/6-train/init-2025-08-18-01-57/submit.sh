sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs1-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=qrpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-qrpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=adamw_torch training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-adamw_torch-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
sbatch -p large512 -t 5:00:00 -N 64 -o reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.out -e reproducibility-scripts/alignment-apertus-swissaiformat/6-train/init-2025-08-18-01-57/out/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0.err ./cscs-shared-submit-scripts/recursive-unattended-accelerate.sh -m post_training.train_preference accelerate_config=src/post_training/configs/accelerate/ds-zero3.yaml dataset=swissai-olmo2-32b-preference dataset_args.dataset_name='\${artifacts_dir}/shared/datasets/alignment-pipeline-swissaiformat/train-datasets/hfformat/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2' model=apertus-70b-sft model_args.model_name_or_path='\${artifacts_dir}/shared/outputs/train_sft/final-run/Apertus70B-tokens15T-longcontext64k-apertus-sft-mixture-7-ln-v2-bs1024-lr2e-06-maxgnorm1-epochs1-ademamix/checkpoints/d0012600a8854237/checkpoint-4462' training_args.max_grad_norm=20 training_args.gradient_accumulation_steps=1 training_args.per_device_train_batch_size=2 training_args.optim=ademamix training_args.learning_rate=5e-07 training_args.loss_type=dpo training_args.normalize_beta_by_length=True training_args.num_ref_rewards=-1 training_args.ref_logprobs_from_dataset=True training_args.beta=5.0 global_batch_size=512 num_nodes=64 job_subdir=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 wandb.run_name=apertus-first-sweep/swissai-olmo2-32b-preference-apertus-70b-sft-mixture-7-d0012600a8854237-maxlen4096-Nref30-logprobs-skywork-llama3-8b-Npairs2-dpo-ademamix-r5e-07-beta5.0 'wandb.tags=[prod,apertus-first-sweep]' artifacts_subdir=shared resuming.resume=True
